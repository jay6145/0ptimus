"""
Demo data management API endpoints
"""
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from pydantic import BaseModel
from typing import Optional, List

from ..database import get_db
from ..utils.demo_data import generate_demo_data
from ..models import (
    Store, SKU, InventorySnapshot, SalesDaily, 
    AnomalyEvent, TransferRecommendation
)

router = APIRouter()

# What generate_demo_data creates (mirrors demo_data.py logic)
DEMO_STORE_NAMES = [
    "Chipotle Athens Downtown",
    "Chipotle Athens Eastside",
    "Chipotle Athens West",
    "Chipotle Athens North",
    "Chipotle Athens South",
]
DEMO_CATEGORIES = [
    "Proteins", "Produce", "Dairy", "Grains & Tortillas",
    "Salsas & Sauces", "Beverages", "Packaging", "Supplies",
]


class DemoDataRequest(BaseModel):
    num_stores: Optional[int] = 5
    num_skus: Optional[int] = 200
    days_history: Optional[int] = 60


@router.get("/demo/preview")
async def get_demo_preview(
    num_stores: int = 5,
    num_skus: int = 200,
    days_history: int = 60,
):
    """
    Return what will be generated by the demo data generator (no DB changes).
    Used by the admin page to show "What will be generated".
    """
    n_stores = min(num_stores, len(DEMO_STORE_NAMES))
    store_names = DEMO_STORE_NAMES[:n_stores]
    # Approximate counts matching demo_data.py logic
    inventory_snapshots_approx = n_stores * num_skus * days_history
    anomalies_approx = min(8, n_stores * 6)
    cycle_recent_pct = 60
    cycle_older_pct = 20
    transfer_skus = min(12, num_skus)
    hourly_days = 14
    hourly_categories = ["Proteins", "Salsas & Sauces", "Produce"]
    telemetry_sensors = 4
    receipt_chance_pct = 20
    return {
        "stores": n_stores,
        "store_names": store_names,
        "skus": num_skus,
        "categories": DEMO_CATEGORIES,
        "days_history": days_history,
        "inventory_snapshots_approx": inventory_snapshots_approx,
        "receipt_chance_pct": receipt_chance_pct,
        "anomalies_approx": anomalies_approx,
        "cycle_recent_pct": cycle_recent_pct,
        "cycle_older_pct": cycle_older_pct,
        "cycle_none_pct": 100 - cycle_recent_pct - cycle_older_pct,
        "transfer_recommendations_approx": f"0–{transfer_skus} (when inventory imbalance > 5×)",
        "sales_hourly_days": hourly_days,
        "sales_hourly_categories": hourly_categories,
        "sales_hourly_skus_per_store": 30,
        "telemetry_sensors": telemetry_sensors,
        "telemetry_description": "Last hour, every 5 min, all stores",
    }


@router.post("/demo/regenerate")
async def regenerate_demo_data(
    request: DemoDataRequest,
    db: Session = Depends(get_db)
):
    """
    Regenerate demo data with specified parameters
    """
    try:
        stats = generate_demo_data(
            num_stores=request.num_stores,
            num_skus=request.num_skus,
            days_history=request.days_history
        )
        
        return {
            "success": True,
            "message": "Demo data regenerated successfully",
            "stats": stats
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"Error generating demo data: {str(e)}"
        }


@router.get("/demo/stats")
async def get_demo_stats(db: Session = Depends(get_db)):
    """
    Get current database statistics
    """
    stats = {
        "stores": db.query(Store).count(),
        "skus": db.query(SKU).count(),
        "inventory_snapshots": db.query(InventorySnapshot).count(),
        "sales_records": db.query(SalesDaily).count(),
        "anomalies": db.query(AnomalyEvent).count(),
        "transfer_recommendations": db.query(TransferRecommendation).count()
    }
    
    # Get date range
    from sqlalchemy import func
    date_range = db.query(
        func.min(InventorySnapshot.ts_date).label('min_date'),
        func.max(InventorySnapshot.ts_date).label('max_date')
    ).first()
    
    if date_range and date_range.min_date:
        stats["date_range"] = {
            "start": date_range.min_date.isoformat(),
            "end": date_range.max_date.isoformat(),
            "days": (date_range.max_date - date_range.min_date).days + 1
        }
    
    return stats
